{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21dcff89",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e30548",
   "metadata": {},
   "source": [
    "* Logistic regression is designed to predict the probability of a given outcome\n",
    "* Outputs continuous values between 0 and 1\n",
    "* Logistic curve is a combination of exponential and parabolic shapes\n",
    "* The function is a sigmoid function and is s-shaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b7a131",
   "metadata": {},
   "source": [
    "### Calculating a Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3cfda6",
   "metadata": {},
   "source": [
    "* The returned probability of logistic regression can be used in either of the two following ways :\n",
    "    * Applied \"as is\", if the model outputs 0.85, there is an 85% probability of whatever is being modeled\n",
    "    * Thresholded, if the model outputs 0.85 and the threshold is set at 0.5, the prediction would be the positive class\n",
    "* The sigmoid function has the formula f(x) = 1 / (1 + e^(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5228881",
   "metadata": {},
   "source": [
    "<img src=\"../pics/sigmoid-function.png\" alt=\"Graph of the sigmoid function\" width=\"550\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3e0d2",
   "metadata": {},
   "source": [
    "* As the input increases, the output of the sigmoid function approaches but never reaches 1\n",
    "* As the input decreases, the output approaches but never reaches 0\n",
    "* The linear component of a logistic regression model is represented as:\n",
    "    * z = b + w1x1 + w2x2 + ... + wnxn\n",
    "* Where:\n",
    "    * z is the output of the linear equation, also called the log odds\n",
    "    * b is the bias\n",
    "    * The w values are the model's learned weights\n",
    "    * The x values are the feature values for a particular example\n",
    "* To obtain the logistic prediction, the z value is then passed through the sigmoid function where:\n",
    "    * y' = 1 / (1 + e^(-z))\n",
    "* Where:\n",
    "    * y' is the output of the logistic regression model\n",
    "    * z is the linear input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4aad03",
   "metadata": {},
   "source": [
    "### Loss and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1d10b",
   "metadata": {},
   "source": [
    "* Logistic regression models are trained using the same process as linear regression models, with two differences\n",
    "    * Logistic regression models use Log Loss as the loss function instead of squared loss\n",
    "    * Applying regularization is critical to prevent overfitting\n",
    "* The Log Loss equation returns the logarithm of the magnitude of the change, rather than just the distance from data to prediction\n",
    "    * Log Loss = $\\sum_{(x,y)} -y \\log(y') - (1 - y) \\log(1 - y')$\n",
    "* Where:\n",
    "    * (x,y) is the dataset containing labeled examples\n",
    "    * y is the label in a labeled example\n",
    "    * y' is your model's prediction\n",
    "* Regularization is a mechanism for penalizing model complexity during training\n",
    "* Without regularization, loss would be driven to 0 in cases where the model has a large number of features\n",
    "* Most logistic regression models use one of the following two strategies to decrease model complexity:\n",
    "    * L2 regulariztion\n",
    "    * Early stopping: limiting the number of training steps to halt training while loss is still decreasing"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
