{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731d8acf",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e3fb8",
   "metadata": {},
   "source": [
    "* Linear Regression is a statistical technique used to find the relationship between variables\n",
    "* In ML context, linear regression finds the relationship between features and a label\n",
    "* In algebraic terms, the model is defined as y = mx + b\n",
    "    * y is the value we want to predict\n",
    "    * m is the slope of the line\n",
    "    * x is the input value\n",
    "    * b is the y-intercept\n",
    "* In ML terms, the model is defined as y' = b + w1*x1\n",
    "    * y' is the predicted value\n",
    "    * b is the bias term\n",
    "    * w1 is the weight for feature x1\n",
    "    * x1 is the input value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84db53",
   "metadata": {},
   "source": [
    "<img src=\"../pics/linear-equation.png\" alt=\"Mathematical representation of a linear model\" width=\"550\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d209a",
   "metadata": {},
   "source": [
    "* A more sophisticated model can be defined as y' = b + w1*x1 + w2*x2 + ... + wn*xn\n",
    "    * y' is the predicted value\n",
    "    * b is the bias term\n",
    "    * w1, w2, ..., wn are the weights for features x1, x2, ..., xn\n",
    "    * x1, x2, ..., xn are the input values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f07e1",
   "metadata": {},
   "source": [
    "### Linear Regression: Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbe34a0",
   "metadata": {},
   "source": [
    "* Loss is a numerical metric the predicts how wrong a model's predictions are\n",
    "* The goal of training a model is to minimize the loss\n",
    "* Loss focuses on the distances between the values, not the direction\n",
    "* Four main types of loss in linear regression:\n",
    "    1. L1 loss\n",
    "        * The sum of the absolute values of the difference between the predicted and actual values\n",
    "        * $\\sum |actual value - predicted value|$\n",
    "    2. Mean Absolute Error\n",
    "        * The average of L1 losses across a set of *N* examples\n",
    "        * $\\frac{1}{N}\\sum |actual value - predicted value|$\n",
    "    3. L2 loss\n",
    "        * The sum of the squared differences between the predicted and actual values\n",
    "        * $\\sum (actual value - predicted value)^2$\n",
    "    4. Mean Squared Error\n",
    "        * The average of L2 losses across a set of *N* examples\n",
    "        * $\\frac{1}{N}\\sum (actual value - predicted value)^2$\n",
    "* When processing multiple examples at once, MAE or MSE is preferred\n",
    "* When choosing the best loss function, consider how you want the model to treat outliers\n",
    "    * MSE moves the model toward outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc9a6a",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf06a0",
   "metadata": {},
   "source": [
    "* Gradient descent is a mathematical technique that iteratively finds the weights and bias that produce the model with the lowest loss\n",
    "* Process of gradient descent\"\n",
    "    1. Calculate the loss with the current weight and bias\n",
    "    2. Determine the direction to move the weights and bias that reduce loss\n",
    "    3. Move the weight and bias values a small amount in the direction that reduces loss\n",
    "    4. Repeat steps 1-3 until the loss stops decreasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd3375",
   "metadata": {},
   "source": [
    "<img src=\"../pics/loss-process.png\" alt=\"Gradient descent is an interative process\" width=\"550\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec88a2",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eee7f3",
   "metadata": {},
   "source": [
    "* Hyperparameters are variables that control different aspects of training\n",
    "* Learning rate is a floating point number that influences how quickly the model converges\n",
    "    * If learning rate is too low, model takes too long to converge\n",
    "    * If learning rate is too high, the model bounces around the weights and bias that minimize the loss and never converges\n",
    "* Learning rate determines that magnitude of the changes to make to the weights and bias during each step of gradient descent\n",
    "    * Gradient multiplied by learning rate to determine parameters for the next iteration\n",
    "* Batch size refers to the number of examples the model processes before updating its weights and bias\n",
    "* Stochastic gradient descent uses only a single example per iteration\n",
    "    * This one example is chosen at random\n",
    "    * Works given enough iterations, but can be noisy\n",
    "* Mini-batch stochastic gradient descent is between SGD and full-batch gradient descent\n",
    "    * Uses a small number of examples per iteration\n",
    "    * Reduces noise while still being efficient\n",
    "* Epoch means the model has processed all examples in the training set once\n",
    "* Number of epochs is the number of times the model processes all examples in the training set\n",
    "    * Given a training set with 1,000 examples and a batch size of 100, the model will take 10 iterations to complete one epoch\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
